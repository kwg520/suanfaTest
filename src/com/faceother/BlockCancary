BlockCanary原理总结

背景
在复杂的项目环境中，由于历史代码庞大，业务复杂，包含各种第三方库，偶尔再来个jni调用，所以在出现了卡顿的时候，我们很难定位到底是哪里出现了问题，即便知道是哪一个Activity/Fragment，
也仍然需要进去里面一行一行看，动辄数千行的类再加上跳来跳去调来调去的，结果就是不了了之随它去了，实在不行了再优化吧。于是一拖再拖，最后可能压根就改不动了，客户端越来越卡。

事实上，很多情况下卡顿不是必现的，它们可能与机型、环境、操作等有关，存在偶然性，即使发生了，再去查那如山般的logcat，也不一定能找到卡顿的原因，是我们自己的应用导致的还是其他应用抢占资源导致的？
是哪些方法导致的？很难去回朔。有些机型自己修改了api导致的卡顿，还必须拿那台机器才能去调试找原因。

BlockCanary就是来解决这个问题的。告别打点和调试，哪里卡顿，一目了然。

dump的信息包括：

基本信息：安装包标示、机型、api等级、uid、CPU内核数、进程名、内存、版本号等
耗时信息：实际耗时、主线程时钟耗时、卡顿开始时间和结束时间
CPU信息：时间段内CPU是否忙，时间段内的系统CPU/应用CPU占比，I/O占CPU使用率
堆栈信息：发生卡慢前的最近堆栈，可以用来帮助定位卡慢发生的地方和重现路径

60fps  -- >  16ms/帧
准则：尽量保证每次在16ms 内处理完所有的cpu 与Gpu 计算，绘制，渲染等操作，否则会造成丢帧卡顿问题

ui卡顿常见原因
1.ui线程中做了轻微的耗时操作
主线程的作用？ActivityThread
把事件分发给合适的view或者widget
2.布局layout 过于复杂 ，无法在16ms内完成渲染，层级多

3.View过度绘制

4.view频繁的触发measure 、layout

5.内存频繁触发GC过多

msg.dispatchMessage(Message msg)  - handlemessage
利用 msg.target.dispatchMessage(msg)的上下方分别打印方法执行时间 ，利用上下的时间差 ，是否是我们设置的卡顿的thresholds 阀值




handler
 acitivy.runOnUithread
 view.post(runnable)
 view.postDelayed(Runable,long)

 DisplayAcitivy.class     displayNotifyCation() = true
 BlockCanaryInternals.setContext

 StackSampler(Looper.getMainLooper().getThread()
 CpuSampler  dump出我们的cpu sampler

 public void start(){
   if(!this.mMointeorstarted){
    this.mMonitorStarted = true ;
    Looper.getMainLooper().setMessageLogging(this.mBlockCanaryCore.monitor)
   }
 }

 StackTraceElement[] var2  = this.mCurrentThread.getStackTrace()

 LinkedHashMap 记录插入顺序

 private boolean isBlock(long endtime){
   return  endTime - this.mStartTimestamp > this.mBlockThresholdMills;
 }




